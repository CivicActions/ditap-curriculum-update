**Program Overview + Structure**

# Welcome to the DITAP Vendor Playbook

This playbook is here to help you deliver the refreshed Digital IT Acquisition Professional (DITAP) program with clarity, confidence, and consistency. The DITAP program is a multi-modal training and development experience delivered over months at a time, built around a cohort-based learning approach that emphasizes collaboration, peer learning, and practical application. Inside, you will find the program structure, key requirements, competency-based content, and essential learning activities, along with tips, tools, and examples to make facilitation smoother and more engaging. While it provides a clear framework to ensure a high-quality experience for every cohort, it also leaves room for you to adapt delivery to your style and your learners’ needs. Think of it as both a guide and a partner, supporting you from planning through delivery so together we can create impactful learning experiences that prepare participants to succeed in real-world acquisition environments.

## Program overview

The Digital Services Credential (DITAP), formerly FAC-C-DS, program aims to train and develop professionals for this certification, focusing on digital service acquisition. It requires a comprehensive approach that includes pre and post-course assessments, multi-modal training delivery utilizing a learning management system, and evaluation based on participation, mastery of content, and a live digital assignment. The program emphasizes a cohort-based learning approach which can be both in-person or fully remote for the majority of facilitation or the majority of content. The curriculum, structured in modules and sprints, covers competencies such as understanding digital services, effective buying techniques, contract administration, and leading change in digital IT acquisition, with the goal of providing participants with practical skill development through real-world application and problem-solving.

## Program structure

The DITAP program is organized to guide participants through a progressive learning journey that blends knowledge building with hands-on application. Its structure combines sequential modules, practical activities, and applied projects in a way that reinforces learning over time. The design ensures that each topic builds on the last, moving participants from understanding core concepts to confidently applying skills in real-world acquisition scenarios.

### Core design principles for delivery

- **Cohort-based learning:** Participants move through the program together, building peer networks, sharing perspectives, and supporting each other’s growth. This sustained engagement is key to the program’s success.
- **Blended, multi-modal delivery:** Learning takes place through a mix of live facilitation, online modules, group discussions, and hands-on assignments.
- **Technology-enabled experience:** Vendors must use a learning management system (LMS) to host course content, track progress, and facilitate discussions. Webinars and other collaboration tools, such as discussion boards or shared workspaces, should be used to enhance interaction and access.
- **Integrated assessment:** Progress is measured through pre- and post-program assessments, active participation, demonstrated mastery of content, and successful completion of a live digital assignment (LDA).
- **Anchor learning in real work**: Use the case study, threaded activities, and Live Digital Assignment to give participants realistic scenarios where they can apply new skills in their own agency context.

### Program modules

The program is divided into five modules, each with multiple sprints that serve as subtopics within the module. These sprints break the content into focused segments, allowing participants to explore specific concepts in depth while building toward the module’s overall learning objectives. The five modules are:

1. **Describe**: Explore what digital services are, who provides them, how they are delivered, and why they are important. Includes an overview of delivery methods (Agile, Human-Centered Design, DevSecOps) and a “Tech Bootcamp” covering data, software, cloud, AI, security, accessibility, and open source.
2. **Discover**: Learn how to assess agency readiness, map stakeholders, define success, and conduct effective market research to inform acquisition strategies.
3. **Design**: Translate discovery insights into a structured solicitation. Covers acquisition strategy development, solicitation creation, and evaluation planning.
4. **Build**: Manage vendor partnerships and guide delivery using agile and lean principles. Topics include performance measurement, kickoff facilitation, and problem resolution.
5. **Grow**: Strengthen the ability to lead change and foster innovation at both the individual and organizational level.

### Target audience

- Required: FAC-C (Professional) holders with at least two years of experience in digital service acquisitions over the FAR 13.500(c) threshold.
- Encouraged: FAC-COR Level II/III and FAC-P/PM Level II/III holders with similar experience, especially those working in cross-functional teams.

## Applicant selection

Selecting the right participants is essential to creating a dynamic learning environment and achieving the program’s intended outcomes. While the DITAP program includes formal eligibility requirements, vendors are encouraged to view applicant selection as an important step in shaping the cohort experience. Thoughtful selection can help ensure that participants bring a mix of relevant experience, motivation, and openness to learning, which in turn supports deeper engagement, richer discussions, and more meaningful application of skills back in the workplace.

### Minimum requirement

All applicants must meet the official Digital Services Credential criteria for enrollment.

### Recommended screening process

Although not required, vendors are encouraged to implement a screening process to assess fit for the program. This can include reviewing application responses, conducting brief interviews, or seeking input from the participant’s supervisor. The goal is to ensure each participant is ready and able to engage fully in the cohort experience.

### Attributes of an ideal candidate

An ideal participant will typically:

- Demonstrate a willingness to experiment, share knowledge, and collaborate with peers.
- Show commitment to applying new skills in their role rather than attending simply to complete a requirement.
- Work in an organization that supports applying the DITAP certification in practice after program completion.
- Have an interest in digital service acquisition, even without a formal IT background.
- Exhibit a positive, change-oriented mindset while acknowledging the realities and challenges of technology acquisition in government.

## Orientation - course start

A strong program launch sets the tone for the entire learning experience. Orientation is an opportunity to establish the cohort community, build connections among participants, and provide a solid foundation for the content to come.

### Optional enhancements

- Cohort Connection: Orientation must be delivered in person to foster a sense of community among participants and reinforce the cohort-based nature of the program.
- Introduction to Agile: A hands-on “Introduction to Agile” activity is required to give participants—especially those without a digital services background—a clear understanding of agile concepts and practices. This can be achieved through experiential exercises such as Play-Doh or LEGO simulations, or other interactive activities that make agile principles accessible and memorable.
- Icebreaker activities
- Guest speakers from government or industry
- Additional activities or topics tailored to the cohort’s needs

### Supporting materials

Orientation materials from the DITAP Refresh are provided in the Refresh GitHub Repo.

## Graduation - course end

Graduation is an opportunity to recognize participant achievement, celebrate the learning journey, and reinforce the value of applying skills back on the job. While not required to be in person, a meaningful closing event can help sustain momentum and strengthen the alumni network.

### Required elements

- **Continuous Learning Points (CLPs):** Participants are eligible to receive 60–80 CLPs based on the delivery approach. Vendors must clearly state in the course materials the total CLPs that can be earned and how they are awarded.
- **Certificate of Completion:** Each participant must receive a training certificate including:
  - Course title
  - Full dates of the course
  - Participant’s full name
  - Name of the organization conducting the training
  - Number of CLPs earned
- **Graduate reporting:** Vendors must submit a final list of all certificate holders to USDS at <techfarhub@omb.eop.gov> so they can be added to the DITAP Alumni listserv.  

### Optional enhancements

- Guest speakers from government or industry
- Special recognition events or activities to mark completion

**USDS review  
**USDS will review the CLP distribution approach, certification format, and graduation activities, whether in person or virtual.

**Supporting materials  
**A sample certificate format is included in the [Appendix](https://docs.google.com/document/d/1-eMOnhw3n8Cl1gPYK3lgMMFxs62SMvREVjkRTJtiZEg/edit?disco=AAABpRUFF1Y&tab=t.ur2oy2nybfia).

## DITAP delivery: required and optional components

To support consistency across all DITAP deliveries, this section below identifies which elements of the program are required versus those that are optional. Required elements form the foundation of the program and ensure participants meet the learning outcomes set by USDS. Optional elements provide flexibility for vendors to enhance delivery with activities and assessments that best fit their facilitation style, participant needs, or agency context.

####

| **Program Element** | **Required / Optional** | **Notes** |
| --- | --- | --- |
| Self-Paced Content | **Required** | All core self-paced modules must be delivered and may be adapted as long as it meets the need of the learning objectives. |
| --- | --- | --- |
| Activities (ILT or exercises) | Optional | Vendors may select or adapt activities to support facilitation style. |
| --- | --- | --- |
| Applied skills assignments | **Required** | Includes shadowing, stakeholder activity, and live digital assignment. |
| --- | --- | --- |
| Threaded case scenario | **Required** | Must be integrated across modules. |
| --- | --- | --- |
| Pre- and post-surveys | Optional | Vendors may administer as part of evaluation, not mandatory. |
| --- | --- | --- |
| Pre- and post-assessments | **Required** | A pre and post assessment must be administered. Vendors have the flexibility to adapt and adjust the choice of assessment as needed. |
| --- | --- | --- |

**Assessment and Grading Requirements**

# Assessment and Grading Guidance

## Overview

As part of the DITAP refresh, assessments have been reimagined to reflect modern principles of adult learning—less about checking boxes, more about building confidence through practice, feedback, and reflection. DITAP assessments are designed to promote meaningful learning behaviors, not just knowledge retention. They help learners apply course concepts to real-world work while giving facilitators insight into learner progress so they can provide timely support.

While this guidance provides a framework for consistent implementation, vendors have discretion to adapt assessments to their delivery format, learner needs, and agency-specific contexts. The goal is to maintain DITAP's core learning objectives while allowing flexibility in how those objectives are assessed and achieved.

### Three core assessment areas

To successfully complete DITAP and earn a certificate, participants must demonstrate growth and competency in:

1. [**Participation**](#_k8ee1jj2p2ly) – Meaningful engagement in course sessions (40% weighting recommended)
2. [**Conceptual Fluency**](#_ya5mrdm3ad9t) – Understanding and application of key DITAP tools and frameworks (30% weighting recommended)
3. [**Live Digital Assignment**](#_3h6vm1c2i02g)– Completing all phases of the Live Digital Assignment (30% weighting recommended)

_Participation should carry the most weight. Vendors may adjust the distribution while maintaining this priority._

### Pass/Fail structure

DITAP uses a pass/fail approach that encourages learners to focus on growth, collaboration, and real-world application rather than chasing points. This reduces performance anxiety and shifts attention toward long-term capability-building—critical behaviors for leading digital transformation.

### Assessment types & design

DITAP includes both formative assessments (low-stakes checkpoints that surface misunderstandings) and summative assessments (final demonstrations of mastery). Formative assessments feed into summative ones, allowing learners to practice, receive feedback, and iterate before final evaluation.

The assessment design is grounded in the Learning-Transfer Evaluation Model (LTEM), which moves beyond attendance and knowledge recall to measuring decision-making, performance in realistic settings, and the foundation for on-the-job transfer and organizational impact.

_See Assessment Framework Section for more information._

## Participation

The participation rubric provides a framework for giving feedback across three dimensions: cohort contribution, connections, and emergent thinking. For each dimension, a participant's engagement is assessed as fully engaged, progressing, or needs attention.

### Participation rubric

|     | **Fully Engaged** | **Progressing** | **Needs Attention** |
| --- | --- | --- | --- |
| **Cohort Contribution** | Consistently contributes in live sessions; builds on others' ideas; prepared and engaged | Occasionally contributes; listens actively; sometimes prepared | Rarely participates or comes unprepared |
| --- | --- | --- | --- |
| **Connections** | Frequently connects course content to real work; shares relevant examples | Makes occasional connections between course and work | Struggles to relate content to context |
| --- | --- | --- | --- |
| **Emergent Thinking** | Regularly introduces new perspectives; demonstrates curiosity and depth | Sometimes surfaces thoughtful ideas | Rarely explores beyond surface-level |
| --- | --- | --- | --- |

### How and when to use the participation rubric

Self-Assessment:

- Participants reflect on their own engagement and identify one area for growth.
- Suggested cadence: Once per module.

Peer Feedback:

- Pairs or small groups provide one observation and one suggestion using rubric language.
- Suggested cadence: Twice per course.

Facilitator Feedback:

- Instructors use the rubric to guide individual or group feedback after observed sessions.
- Suggested cadence: Twice per course.

The rubric should be used during or immediately after interactive sessions, especially those tied to the threaded case scenario, where deeper engagement and discussion are expected.

### What to do when a participant's participation needs attention

A facilitator check-in should be scheduled when a participant meets either of the following criteria:

- Two consecutive "Needs Attention" ratings in the same dimension; OR
- Three total "Needs Attention" ratings across any dimension during the program

Use the rubric to guide the conversation and offer concrete ways to re-engage.

## Conceptual fluency

Conceptual fluency is the ability to understand, apply, and clearly communicate key DITAP tools and frameworks—such as the Digital Services Playbook, TechFAR, and human-centered design principles—in realistic work contexts.

### How conceptual fluency is assessed

#### Pre- and Post-Assessments

Pre- and post-course assessments bookend the DITAP learning experience, helping participants and facilitators measure growth, identify focus areas, and align learning activities to real-world application. While neither is graded, they provide valuable benchmarks that guide ongoing support and reflection.

- 1. Pre-Assessment: Surfaces baseline understanding and confidence with DITAP tools and frameworks. Helps facilitators anticipate support needs and tailor early instruction.
  2. Post-Assessment: Captures growth in conceptual fluency, confidence, and applied decision-making. Comparing results offers participants a clear view of their progress.

Baseline assessments are provided. Pre and post assessments are required. Vendors may amend scenarios or questions but should ensure consistent administration for comparable results across cohorts.

#### Knowledge Checks

Knowledge checks are embedded throughout the self-paced modules to help learners identify misconceptions early, practice applying key concepts, and reinforce terminology, frameworks, and decision-making skills. They are strategically placed in modules that introduce complex material to help manage cognitive load and confirm comprehension before learners advance.

**Key characteristics:**

- **Formative, not summative** – Low-stakes and non-graded; their purpose is reflection and reinforcement, not compliance. Completion is not required to move forward, but vendors must track participation and performance patterns to guide facilitation.  

- **Integrated for reinforcement** – Aligned to module objectives and placed where content is most critical to help learners connect theory to practice in real time.  

- **Flexible implementation** – May be referenced in live facilitation, supplemented with additional checks, or adapted for agency-specific scenarios.  

#### Applied learning assignments and in-class discussions

Three core applied learning opportunities serve as checkpoints for conceptual fluency:

- Stakeholder Research Assignment
- Shadowing Assignment
- In-Class Discussions of the Threaded Case Scenario

These assignments, in addition to other interactive class discussions, give facilitators insight into each learner's understanding and integration of course concepts. They must be evaluated holistically using the Conceptual Fluency Rubric.

#### Conceptual Fluency Rubric

| **Level** | **Description** |
| --- | --- |
| **Fully Demonstrated** | Accurately explains key frameworks and terminology (e.g., TechFAR, Playbook); effectively applies course concepts in the stakeholder research assignment, shadowing assignment, and threaded case scenario; performs well on knowledge checks. |
| --- | --- |
| **Progressing** | Demonstrates partial understanding of course content; applies some concepts with growing consistency across applied learning assignments; knowledge checks reveal occasional gaps |
| --- | --- |
| **Needs Attention** | Struggles to explain or apply core concepts; responses in applied learning assignments are vague, inaccurate, or disconnected from course frameworks; knowledge check performance indicates significant misunderstandings. |
| --- | --- |

###

###

###

###

### How and when to use the conceptual fluency rubric

Facilitators should use the rubric throughout the course, assessing conceptual fluency in applied assignments, live discussions, and reflections. A holistic review should be conducted at the end of each module.

**Recommended cadence:**

- **Bi-weekly:** Provide feedback on assignments and self-paced work.
- **End of module:** Assign a formal rating and document progress.
- **Ongoing:** Act on repeated "Needs Attention" patterns immediately.

When a participant receives "Needs Attention" ratings, facilitators should hold a supportive check-in and offer concrete strategies such as revisiting key readings, allocating more time for coursework, leveraging peer discussions, or using AI tools to explore concepts further.

## Live Digital Assignment

The Live Digital Assignment (LDA) is the capstone experience of the DITAP course. It gives participants the opportunity to simulate the lifecycle of a digital services acquisition and apply key DITAP concepts in a real-world context.

Throughout the LDA, learners:

- Practice stakeholder engagement through real or simulated interviews
- Scope problems using HCD and Discovery Sprint tools
- Simulate vendor roles by preparing a case study response
- Evaluate peer submissions using real-world criteria
- Reflect on lessons learned through final team presentations

The four LDA phases include:

1. **Discovery sprint** – Problem framing through stakeholder interviews
2. **Case study development** – Creation of four artifacts aligned to the SPRUCE Technical Factor
3. **Peer evaluation** – Blind review and feedback using a rubric
4. **Final presentations** – Team reflections and learning synthesis

The Case Study Package is formally assessed as Pass/Fail, but each phase is essential to the learning experience and course completion.

**Suggested assessment breakdown:**

- Case Study Package: 35%
- Peer Evaluation: 25%
- Team Presentation: 25%
- Team Reflection: 15%

Vendors should refer to the LDA Facilitator Guide for detailed phase-by-phase instructions, templates, and assessment guidance.

## Assessment Framework

### The Learning-Transfer Evaluation Model (LTEM)

DITAP assessments are intentionally designed using the Learning-Transfer Evaluation Model (LTEM), created by Will Thalheimer. LTEM provides a framework for measuring learning effectiveness beyond attendance or satisfaction surveys, progressing from basic measures of participation and engagement (Levels 1–3) to deeper measures of knowledge, decision-making, and performance (Levels 4–6), and ultimately to transfer and organizational results (Levels 7–8).

### LTEM alignment in DITAP

DITAP's three assessment areas are strategically aligned with multiple LTEM levels:

### Participation (LTEM levels 1-2)

The participation rubric ensures meaningful application of content that prepares participants to bring what they've learned into their work.

### Conceptual fluency (LTEM levels 4-5)

- Level 4 (Knowledge): Pre/post assessments and knowledge checks assess recall and accurate description of key concepts
- Level 5 (Decision-Making): Applied learning assignments and scenario-based activities require selecting appropriate actions in realistic situations

### Capstone project (LTEM level 6)

The Live Digital Assignment operates at Level 6 (Task Competence) by requiring learners to perform actual behaviors and apply processes they will use on the job in a realistic, end-to-end simulation. This includes integrating multiple DITAP tools, making trade-off decisions, and producing deliverables that meet professional standards.

### Progressive skill building

This LTEM-aligned structure creates a scaffolded learning experience. Participation and early conceptual fluency activities establish engagement and basic knowledge. Knowledge checks and applied assignments provide low-stakes opportunities to practice decision-making. The capstone project demonstrates comprehensive ability to perform in realistic conditions.

### Beyond the course: transfer and impact

While LTEM Levels 7 (Transfer) and 8 (Organizational Results) are not directly measured within the course, successful completion of DITAP's assessment structure positions participants to achieve these higher levels after the program concludes.

_See Appendix for detailed LTEM level descriptions with DITAP examples._

## Pass/Fail implementation guidance

### Standard pass/fail criteria (applies to all assessment areas)

- **Fully Engaged/Demonstrated:** Clear evidence of meeting expectations; learner is on track to pass
  - Examples: Consistently contributes in discussions, accurately applies frameworks in assignments, completes all phases of the capstone project, demonstrates growth in post-assessment results.
- **Progressing:** Generally on track; continue to encourage reflection and consistency
  - Examples: Contributes occasionally, applies some frameworks with partial accuracy, completes most but not all deliverables, post-assessment results show some improvement but reveal gaps.
- **Needs Attention:** May be at risk; facilitator should initiate a check-in and support plan
  - Examples: Rarely participates, struggles to apply frameworks in assignments, misses key deliverables, receives multiple “Needs Attention” ratings on rubrics, or shows little to no progress from pre- to post-assessment.

### Vendor assessment requirements summary

In summary, each vendor must implement an assessment plan that supports the pass/fail nature of the course and includes:

- **Meaningful participation measurement** using engagement rubrics and opportunities for ongoing feedback.
- **Consistent informal and formal measurement of conceptual fluency** across multiple course elements, including:
  - Administration of pre-course and post-course assessments
    - DITAP Pre-Program Survey: The purpose of this survey is to measure participants’ incoming knowledge and experience related to the key competencies in the Digital IT Acquisition Professional (DITAP) program.
    - DITAP Post-Program Survey: This post-program survey is designed to collect participant feedback on the program’s content, delivery, and value to your professional development.
  - Knowledge checks embedded in the self-paced modules
  - Applied learning assignments such as shadowing and stakeholder research and in-class discussions such as those related to the threaded case scenario
- **A cumulative, culminating applied learning assignment (capstone)** that simulates real-world digital acquisition challenges.

Vendors may supplement with additional assessments based on their delivery format, learner preferences, or agency-specific use cases.

## Continuous Learning Points (CLPs)

Participants in the full 6-month DITAP program should be eligible to receive 80 CLPs upon successful completion of all program requirements.

For shorter or adapted versions of the program, training providers should work with USDS to determine the appropriate CLP allocation. The total number of CLPs and the criteria for earning them should be clearly stated in the course materials provided to participants.

##

## Appendix

###

### “Participation needs attention” sample email

**Subject:** Quick check-in on participation

Hi \[Student Name\],

I wanted to touch base about your participation in the DITAP course. Based on recent reflections and observations, it looks like your participation in the course needs attention. As you know, participation means contributing to discussions, connecting course material to your day-to-day work, and surfacing emerging insights. When those opportunities are missed, it becomes harder to get the full value of the course.

This isn't about being the most vocal person—it's about showing up in ways that support your learning and the group's. I'd love to help you get more out of the rest of the course. If you're open to it, let's connect and talk through what might help.

Warmly, \[Facilitator/Vendor Name\]

### Sample reflective coaching prompts

- What's one way you've contributed to others' learning in the course so far?
- What connections have you been making between this session and your work?
- What's one question or insight you want to keep exploring?

### Learning-Transfer Evaluation Model (LTEM) with DITAP examples

| **LTEM Level** | **Description** | **DITAP Examples** |
| --- | --- | --- |
| **1\. Participation** | Learners are present for live sessions and complete required self-paced modules. | Zoom attendance logs; LMS completion records; average learning time. |
| --- | --- | --- |
| **2\. Engagement** | Learners actively engage with required learning activities and assignments. | Time spent in lessons; whether videos are watched in full vs. fast-forwarded; frequency and quality of questions asked during live sessions; self-paced knowledge check completion; assignment submission (before feedback). |
| --- | --- | --- |
| **3\. Learner Perceptions** | Learners report the relevance, quality, and effectiveness of the course. | End-of-course survey; mid-course pulse check; reflections on perceived skill growth and confidence. |
| --- | --- | --- |
| **4\. Knowledge** | Learners recall and accurately describe key facts, terms, and frameworks tied to course outcomes. | Knowledge checks in self-paced modules; accurate use of terminology in class; conceptual fluency demonstrated during discussions.<br><br>E.g., You’re managing a software development contract with multiple vendor teams. Which agile practice will help ensure visibility into progress and performance? |
| --- | --- | --- |
| **5\. Decision - Making** | Learners choose appropriate actions or solutions in realistic scenarios. | Responses in the threaded case scenario; scenario-based knowledge checks; decision-making prompts in live sessions; conceptual fluency shown when weighing trade-offs or justifying choices.<br><br>E.g., Scenario review: A federal agency redesigned its benefits application portal after user research revealed that many applicants found the previous version confusing and inaccessible. Choose the appropriate next step. |
| --- | --- | --- |
| **6\. Performance (in learning environment)** | Learners demonstrate skills effectively in realistic but low-risk practice settings. | Conducting stakeholder interviews; applying HCD tools in problem-framing exercises; delivering LDA case study presentations; all applied learning assignments.<br><br>E.g., create a sprint backlog |
| --- | --- | --- |
| **7\. Transfer (on the job)** | Learners apply new skills and approaches in their real work environment. | Alumni survey 30–60 days post-course asking for specific examples; manager interviews to confirm observed behavior changes. |
| --- | --- | --- |
| **8\. Results** | Tangible, measurable organizational or mission-level improvements linked to the learning. | Agency reports of faster procurement cycles, cost savings, improved collaboration, or time savings tied to DITAP graduates; documented ROI of learning initiatives. |
| --- | --- | --- |

**Module Overview**

# Module Content Overview

## Module 0: Orientation

<table><thead><tr><th colspan="3"><p><strong>Module 0: Describe</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 1: The Digital Services Landscape</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Program Overview and</p><p>Navigation</p></th><th colspan="2"><p>This topic provides an overview of the DITAP training program, including its structure, learning objectives, and key curriculum components. Learners will gain clarity on how the course is organized, what to expect from each module, and how the program supports their development as digital service acquisition professionals.</p></th><th><p>N/A</p></th></tr><tr><th><p>Learning How to Learn</p></th><th colspan="2"><p>This topic introduces the principles of adult learning and the mindset needed for success in an applied, collaborative training environment. Learners will explore strategies for managing time, workload, and personal growth as they engage with hands-on activities and peer-driven discussions throughout the course.</p></th><th><p>Develop an understanding of how adult learning principles, personal learning strategies, and mindset shifts support success in a collaborative, experiential course environment.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Structure of the DITAP program</li><li>Learning objectives and competencies</li><li>Key curriculum components and modules</li><li>How to navigate course materials and resources</li><li>What to expect from program pacing and delivery</li><li>Principles of adult learning</li><li>Mindset for success in a collaborative environment</li><li>Strategies for time and workload management</li><li>Approaches to personal growth and reflection</li><li>Making the most of hands-on activities and peer discussions</li></ul></th></tr></thead></table>

## Module 1: Describe

Describe: Explore digital services in the 21st century, including what they are, who provides them, how they are delivered, and why they are important.

<table><thead><tr><th colspan="3"><p><strong>Module 1: Describe</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 1: The Digital Services Landscape</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>What is Digital Service?</p></th><th colspan="2"><p>This topic introduces the foundational concepts of digital services within the federal landscape. Learners will recognize key characteristics of digital services, explore common examples in government, and build a basic understanding of the underlying systems and architecture that support their delivery.</p></th><th><p>Define digital services and the problems they can be used to solve.</p></th></tr><tr><th><p>Digital Services in Government</p></th><th colspan="2"><p>This topic introduces key players in the digital services ecosystem, both within government and in the private sector. Learners will identify major organizations and roles involved in digital service delivery and explore foundational resources such as the U.S. Digital Services Playbook and the TechFAR Handbook to understand their relevance to federal procurement practices.</p></th><th><p>Identify "who's who" in the digital services arena, including public and private sector organizations and individuals; Identify and understand the Digital Service Playbook and TechFAR Handbook concepts.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Digital Services - The Who and What</li><li>Then and Now: USCIS.gov Use Case</li><li>Defining Digital Services: Another Take</li><li>The Digital Services Ecosystem</li><li>The Digital Services Ecosystem, Part 2</li><li>Who’s Who: A Starting List</li><li>Activity Break (Optional)</li><li>Recommended Readings</li><li>Case Study Tie In: Module 1 Activity: Introducing Casey and the CRM Project</li></ul></th></tr></thead></table>

<table><thead><tr><th colspan="3"><p><strong>Module 1: Describe</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 2: Digital Service Methods, Roles and Sources of Supply</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Digital Service Delivery Methods 1: Agile</p></th><th colspan="2"><p>This topic introduces agile software delivery as a foundational approach to modern digital services. Learners will compare agile and traditional (waterfall) development methods, explore core agile principles, and examine key team roles, ceremonies, and practices that enable iterative and user-centered delivery.</p></th><th><p>Identify modern design, development, and delivery methods used by digital services professionals.</p></th></tr><tr><th><p>Digital Service Delivery Methods 2: Design / User Centered Design/DevSecOps</p></th><th colspan="2"><p>This topic explores complementary practice areas that strengthen agile digital delivery. Learners will examine user-centered design, DevSecOps, and related private sector practices that contribute to secure, iterative, and user-focused software development in government contexts.</p></th><th><p>Identify modern design, development, and delivery methods used by digital services professionals.</p></th></tr><tr><th><p>Digital Service Delivery Providers: Sources of Supply</p></th><th colspan="2"><p>This topic provides an overview of the current landscape of digital service providers. Learners will identify key government-led digital service organizations and understand how private sector vendors contribute to delivery. The topic also introduces sourcing considerations relevant to federal acquisition professionals evaluating potential partners.</p></th><th><p>Identify "who's who" in the digital services arena, including public and private sector organizations and individuals.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Digital Services – The How (Introduction)</li><li>Learn About Your Users’ Needs</li><li>Learn About Your Users’ Needs Cont'd</li><li>Contemporary Practices in Developing Digital Services</li><li>Digital Service Delivery Methods: Agile</li><li>Digital Service Delivery Methods: HCD and DevSecOps</li><li>Activity: Create a Sprint Backlog</li><li>Digital Service Delivery Providers: Sources of Supply</li></ul></th></tr></thead></table>

<table><thead><tr><th colspan="3"><p><strong>Module 1: Describe</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 3: Digital Service Tech Bootcamp</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Introduction to Digital Service Tech Bootcamp</p></th><th colspan="2"><p>This topic provides a high-level overview of the core technologies behind digital service delivery. Learners will gain foundational awareness of data, software, cloud, AI, and cybersecurity to better understand technical proposals and engage with digital service teams during the acquisition process.</p></th><th><p>Identify and describe core technology domains that underpin digital service delivery, including data, software, cloud computing, artificial intelligence, and cybersecurity.</p></th></tr><tr><th><p>Tech Topic 1: Data</p></th><th colspan="2"><p>This topic introduces the role of data in digital service delivery. Learners will explore different types of data, how data is stored, shared, and managed within government systems, and the importance of open data, privacy, and security. Key considerations related to data lifecycle management and compliance will also be discussed.</p></th><th><p>Explain key concepts related to data in digital services, including data types, storage, sharing, open data, privacy, and compliance considerations.</p></th></tr><tr><th><p>Tech Topic 2: Software</p></th><th colspan="2"><p>This topic examines the software landscape in government procurement, including commercial software (COTS and SaaS), custom software development, and delivery models. Learners will identify key roles in software delivery, understand software acquisition considerations, and explore relevant policy areas that shape buying decisions.</p></th><th><p>Identify modern software design, development, and delivery methods used by digital service professionals, and describe key acquisition considerations across COTS, SaaS, and custom solutions.</p></th></tr><tr><th><p>Tech Topic 3: Cloud</p></th><th colspan="2"><p>This topic provides an overview of cloud computing in the federal environment. Learners will explore different types of cloud services, benefits and challenges of cloud adoption, and the policy frameworks that govern cloud usage in government digital service delivery.</p></th><th><p>Explain the benefits, challenges, and types of cloud services, and describe relevant policies that shape cloud adoption in government.</p></th></tr><tr><th><p>Tech Topic 4: AI</p></th><th colspan="2"><p>This topic introduces learners to the current landscape of AI tools and models used in digital services. Learners will examine foundational concepts, applications in government, and key policy issues such as transparency, bias, privacy, and responsible AI use.</p></th><th><p>Describe the current landscape of AI tools and models, and explain key policy considerations including transparency, bias, and responsible use.</p></th></tr><tr><th><p>Tech Topic 5: Security</p></th><th colspan="2"><p>This topic explores essential principles of cybersecurity in digital service delivery. Learners will review concepts such as identity and access management (IAM), vulnerability management, continuous monitoring (e.g., SIEM), and compliance frameworks. The topic also connects these principles to relevant federal policies and acquisition considerations.</p></th><th><p>Identify foundational cybersecurity concepts such as IAM, vulnerability management, and compliance frameworks, and explain their relevance to digital service delivery.</p></th></tr><tr><th><p>Tech Topic 6: Accessibility</p></th><th colspan="2"><p>This topic explores essential concepts of accessibility in digital service delivery, emphasizing its importance in federal procurement. Learners will examine how accessibility ensures digital products and services are usable by all individuals, including those with disabilities, and how it benefits a wider audience such as seniors and veterans. The topic also covers common misunderstandings, the integration of accessibility throughout the acquisition lifecycle, key laws and standards like Section 508 and WCAG 2.2, and available tools and templates to improve accessibility outcomes in procurement.</p></th><th><p>Recognize the essential concepts of accessibility in digital services procurement, Identify common misunderstandings about accessibility and how to address them, Recognize the importance of ongoing accessibility maintenance throughout a project's lifecycle, Use federal tools and templates to improve accessibility outcomes in your procurements</p></th></tr><tr><th><p>Tech Topic 7: Open Source</p></th><th colspan="2"><p>This topic introduces procurement officers to the principles, risks, and opportunities of open source software (OSS) in digital government. It covers how OSS reduces costs, increases innovation, and supports vendor independence. Key areas of discussion include legal foundations, evaluation practices, and the role of OSS in long-term service delivery and transparency, addressing common misunderstandings and its integration into the acquisition lifecycle.</p></th><th><p>Recognize how open source software fits within federal procurement, Identify common myths and misunderstandings around OSS in government, Explain how open source software fits into Commercial Off-the-Shelf (COTS) procurement</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><p><strong>Tech Topic 1: Data</strong></p><ul><li>What is data?</li><li>Key Considerations for Government Systems</li><li>Open Data</li><li>Data Privacy</li></ul><p><strong>Tech Topic 2: Software</strong></p><ul><li>What is software?</li><li>How is software developed?</li><li>How is software delivered?</li><li>How is software updated?</li><li>Considerations around Supply Chain Licensing</li><li>Service Design and Delivery Standards</li></ul><p><strong>Tech Topic 3: Cloud</strong></p><ul><li>Basics</li><li>Considerations</li><li>Why Understanding Cloud Computing is Critical for Government Contracting Officers</li><li>Bottom Line for Contracting Officers</li></ul><p><strong>Tech Topic 4: AI</strong></p><ul><li>What Is Artificial Intelligence?</li><li>Types of AI</li><li>Key Considerations for Government Systems</li><li>Common AI Terms You May Encounter</li><li>Why It Matters to Procurement Officers</li><li>"What Contracting Officers Should Keep in Mind"</li></ul><p><strong>Tech Topic 5: Security</strong></p><ul><li>Why is Cybersecurity Important?</li><li>Cybersecurity in the current federal procurement context</li><li>Four Key Areas of Cybersecurity for Digital Services</li></ul><p><strong>Tech Topic 6: Accessibility</strong></p><ul><li>Must Know Concepts</li><li>Common Misunderstandings</li><li>Where Does Accessibility Show Up?</li><li>Key Laws, Standards, or Frameworks</li></ul><p><strong>Tech Topic 7: Open Access</strong></p><ul><li>Must Know Concepts</li><li>Common Misunderstandings</li><li>Why OSS Shifts Power Back to Government</li><li>How Open Source Shows Up in the Acquisition Lifecycle</li><li>Key Laws, Standards, or Frameworks</li></ul></th></tr></thead></table>

## Module 2: Discover

Discover: Engage in a discovery process to set the foundation for informed acquisition strategy decisions. By assessing organizational maturity, identifying key stakeholders, analyzing mission and user needs, evaluating risks, and performing market research, you will gather the data necessary to shape a successful digital service procurement.

<table><thead><tr><th colspan="3"><p><strong>Module 2: Discover</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 1: Assessing Agency Readiness</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Assessing Agency Readiness</p></th><th colspan="2"><p>This sprint introduces tools and strategies to evaluate an agency’s readiness to pursue a digital service procurement. Learners will assess internal capacity including staffing, technical expertise, and leadership alignment while using frameworks such as the digital service maturity matrix to identify areas of strength and improvement.</p></th><th><p>Assess your agency’s capacity, maturity, and alignment to support a successful digital service procurement.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Introduction to Assessing Agency Readiness</li><li>Determine Your Organizational Maturity</li><li>Strategy Table in Practice</li><li>Change and Innovative Readiness Survey Introduction</li><li>Change and Innovative Readiness Survey (in class / fillable)</li></ul></th></tr></thead></table>

<table><thead><tr><th colspan="3"><p><strong>Module 2: Discover</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 2: Stakeholder and Customer Mapping</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Stakeholder and Customer Mapping</p></th><th colspan="2"><p>This sprint focuses on identifying and engaging the individuals and groups who influence or are impacted by a digital service procurement. Learners will differentiate between stakeholders, users, and customers, and begin mapping relationships to better align acquisition strategies with mission needs and user outcomes.</p></th><th><p>Identify key stakeholders, users, and customers relevant to your acquisition and analyze their roles, influence, and engagement needs.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Navigating the Stakeholder Landscape: Introduction</li><li>Navigating the Stakeholder Landscape Cont'd</li><li>Role Play Activity: Stakeholder Influence Challenge</li><li>Activity: Stakeholder Analysis Project Introduction</li></ul></th></tr></thead></table>

<table><thead><tr><th colspan="3"><p><strong>Module 2: Discover</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 3: Defining Success for Your Digital Services Acquisition</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Defining Success for Your Digital Services Acquisition</p></th><th colspan="2"><p>This sprint helps learners define what success looks like for a digital service acquisition. Learners will develop product visions, user stories, and outcome-oriented objectives to clarify mission needs. The sprint also introduces methods for identifying constraints such as policy, technology, or capacity that may impact delivery, and offers tools to frame success criteria beyond traditional compliance metrics.</p></th><th><p>Develop a shared understanding of your agency’s needs and constraints, and define success criteria for your digital service procurement.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Defining Success for your Digital Services Acquisition Overview</li><li>From Discovery to Strategy</li><li>Defining Constraints Before Acquisition Strategy Begins</li></ul></th></tr></thead></table>

<table><thead><tr><th colspan="3"><p><strong>Module 2: Discover</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 4: Conducting Effective Market Research</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Conducting Effective Market Research</p></th><th colspan="2"><p>This sprint focuses on strategies for conducting meaningful market research in support of digital service procurements. Learners will explore how to assess industry capabilities, craft early needs statements, and apply research methods such as RFIs to inform acquisition planning. Emphasis is placed on minimizing burden to vendors while gathering actionable insights to shape a more responsive and competitive solicitation.</p></th><th><p>Apply effective market research strategies to assess vendor capabilities and inform your digital acquisition approach.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Introduction to Conducting Effective Market Research</li><li>Introduction to Building Your Market Research Toolkit</li><li>Acquisition Toolkit Worksheet</li><li>The Magic Quadrant</li><li>Responsible Pre-Solicitation Communication</li><li>Acquisition Process Myths</li><li>Why Pre-Solicitation Communication Matters</li><li>Knowledge Check</li><li>How to Communicate Effectively</li><li>How to Communicate Effectively: Step 2</li><li>Engaging the Industry Traditionally</li><li>Activity: Signal or Noise? Evaluating RFIs with AI Insight</li><li>How to Communicate Effectively: Step 3</li><li>Understand the Cost-Benefit and Tradeoffs</li><li>Conclusion: Leveraging HCD and AI in Federal Market Research</li></ul></th></tr></thead></table>

##

## Module 3: Design

Design: Translate your discovery findings into a well-structured solicitation. Create acquisition strategy decisions around tradeoffs, evaluation processes, contract structure, and performance metrics which lead to the development of requirements, solicitation factors, and evaluation criteria that support user-centered outcomes and successful vendor partnerships.

<table><thead><tr><th colspan="3"><p><strong>Module 3: Design</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 1: Developing a Successful Acquisition Strategy</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Developing a Successful Acquisition Strategy</p></th><th colspan="2"><p>This sprint guides learners through the key elements of developing a digital acquisition strategy. Topics include making informed build-versus-buy decisions, selecting appropriate procurement methods (e.g., OTAs, GWACs, 8(a), CSO), and structuring modular contracts to support iterative delivery. Learners will also examine contract types, performance-based incentives, outcome measurement tools such as burndown and velocity charts, and considerations related to data rights and long-term reuse.</p></th><th><p>Identify how to apply flexibilities within the FAR to develop an acquisition strategy tailored for digital services.</p><p>Select appropriate evaluation methods and criteria related to cost, pricing, terms and conditions, cybersecurity, and data rights.</p><p>Assess vendor maturity and capability to deliver a digital product based on defined needs and success criteria</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Introduction: Developing an Acquisition Strategy</li><li>Why Do We Plan?</li><li>What Feeds the Acquisition Strategy?</li><li>The Acquisition Plan Lean Canvas Approach</li><li>Common Risks</li><li>Contract Exit Strategies</li><li>Stakeholder Engagement: Capability and Cooperation</li><li>Existing Contracts</li><li>Streamline the Process</li><li>Considerations for a New Contract</li><li>Funding and Programmatic Considerations</li><li>State of the Market</li><li>Compliance &amp; Other Legal Issues</li><li>Getting to Know Your Office of General Counsel</li><li>What is Intellectual Property?</li><li>Types of IP</li><li>FAR Subpart 27.4 Rights in Data and Copyrights</li><li>Contribution, Attribution, Retribution...Oh My!</li><li>Who Owns Open Source Code?</li><li>Data in the Cloud (It's Cloudy Out There!)</li><li>Legal Liabilities</li><li>What Happens When Open Source Software Breaks?</li><li>Case Study Tie In Module 3 Activity: Solution Evaluation with SWOT Analysis</li><li>Multi-vendor Contracts</li></ul></th></tr></thead></table>

<table><thead><tr><th colspan="3"><p><strong>Module 3: Design</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 2: Developing the solicitation</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Developing the solicitation</p></th><th colspan="2"><p>This sprint focuses on developing the core elements of a digital service solicitation to drive successful acquisition outcomes. Learners will explore how to write a Statement of Objectives (SOO), apply appropriate award procedures under the FAR and non-FAR authorities, and incorporate pricing strategies and evaluation language aligned with outcome-based delivery. The sprint also examines emerging considerations such as the role of AI in acquisition and the balance between key personnel and performance outcomes.</p></th><th><p>Develop key elements of a digital service solicitation, including a Statement of Objectives (SOO), appropriate award procedures, and outcome-oriented evaluation factors.</p><p>Evaluate how pricing structures, key personnel requirements, and emerging technologies such as AI may impact solicitation strategy and vendor response.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Strategic Planning and Execution in Digital Acquisitions</li><li>Developing a Statement of Objectives (SOO)</li><li>Key Sections of an SOO homework assignment (template)</li><li>Understanding FAR 37.6: How Does Agile Methodology Fit Into Federal Acquisitions?</li><li>Key Personnel vs Outcome-based</li><li>Artificial Intelligence and the Acquisition Strategy</li><li>Discussion</li><li>7 Strategies for Evaluating the Ethical and Legal Impact of Implementing AI in Federal Agencies</li></ul></th></tr></thead></table>

<table><thead><tr><th colspan="3"><p><strong>Module 3: Design</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Spring 3: Running a Successful Evaluation</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Running a Successful Evaluation</p></th><th colspan="2"><p>This sprint prepares learners to run effective evaluations of vendor proposals in digital service procurements. Learners will explore how to define and apply technical evaluation criteria, select a skilled evaluation team, and use debriefing and negotiation techniques to support tradeoff decisions, strengthen vendor relationships, and ensure transparent, mission-aligned outcomes.</p></th><th><p>Evaluate agile vendors using solicitation criteria, oral presentations, and past performance to assess alignment with agile practices and technical requirements.</p><p>Design and apply evaluation strategies that incorporate down-selects, interactive techniques, and tradeoff approaches to support fair and best-value acquisitions.</p><p>Deliver effective post-evaluation feedback that builds trust, strengthens future proposals, and aligns with FAR guidance.</p><p>Conduct strategic vendor negotiations that clarify assumptions, manage risks, and secure best-value outcomes in digital service procurements.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Evaluation Criteria Overview</li><li>Negotiating with Vendors</li><li>Knowledge Check</li><li>The Power of Debriefing</li></ul></th></tr></thead></table>

## Module 4: Build

Build: Manage vendor partnerships and support delivery through contract administration practices grounded in agile and lean methodologies. Track project health using real-time, objective indicators, support continuous delivery, and adapt to change while ensuring alignment with mission goals. Focus on transparency, collaboration, and outcomes throughout the contract lifecycle.

<table><thead><tr><th colspan="3"><p><strong>Module 4: Build</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 1: Management of Digital Service Delivery</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Management of Digital Service Delivery</p></th><th colspan="2"><p>This sprint introduces key roles and practices that support effective post-award delivery of digital services. Learners will explore the function of product ownership, how product managers and contracting officer representatives (CORs) collaborate, and how agile ceremonies and tools support iterative delivery. The sprint also emphasizes cross-functional team alignment and the importance of celebrating shared successes.</p></th><th><p>Describe what product ownership looks like in federal digital service delivery environments.</p><p>Explain how contracting officer representatives (CORs) and product owners (POs) collaborate to support agile delivery.</p><p>Recognize the importance of communication, shared understanding, and agile rituals in effective digital service teams.</p><p>Identify ways to celebrate progress and success across cross-functional teams.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Managing Digital Service Delivery</li><li>Amplifying Agile Delivery</li><li>Activity: Who Does What? Agile Role Round Robin</li><li>Activity: Digital Service Project Charter</li></ul></th></tr></thead></table>

<table><thead><tr><th colspan="3"><p><strong>Module 4: Build</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 2: Performance Measurement Under Agile Delivery Contracts</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Performance Measurement Under Agile Delivery Contracts</p></th><th colspan="2"><p>This sprint explores how to measure performance in agile digital service contracts using meaningful, real-time metrics. Learners will examine approaches that go beyond traditional compliance tools like the QASP, including milestone tracking, contractor self-reporting, CPARS, and quarterly performance reviews. The sprint also covers strategies for incentivizing outcomes and monitoring vendor performance in multi-vendor environments.</p></th><th><p>Identify and apply performance metrics that help detect delivery risks or failure points early in agile digital service contracts.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Using Value-Based Metrics and Modern Incentives in Federal Agile Procurement</li><li>Post-Award Multi-Vendor Management</li><li>Knowledge Check: Managing a Multi-Vendor Environment</li><li>Warranties in Agile Development Readings</li></ul></th></tr></thead></table>

<table><thead><tr><th colspan="3"><p><strong>Module 4: Build</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 3: Contract Kickoff</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Contract Kickoff</p></th><th colspan="2"><p>This sprint focuses on how to successfully launch a digital services contract. Learners will explore strategies for preparing both government and vendor teams, setting clear expectations, aligning on scope and delivery approach, and establishing communication and collaboration rhythms that support agile execution from day one.</p></th><th><p>Determine the key activities that occur after contract award, including kickoff planning, team ramp-up, and establishing a shared delivery baseline.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Contract Kickoff</li><li>Introduction to Readings: Cloud and Xaas Procurement Best Practice</li><li>Activity: Cloud Breach Facilitation Exercise Facilitation Guide</li></ul></th></tr></thead></table>

<table><thead><tr><th colspan="3"><p><strong>Module 4: Build</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 4: Contract Management and Problem Resolution</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Contract Management and Problem Resolution</p></th><th colspan="2"><p>This sprint focuses on managing digital service contracts after award, with an emphasis on identifying and addressing performance issues. Learners will explore techniques for monitoring vendor progress, resolving delivery challenges, and applying remedies within the bounds of the contract. The sprint also highlights the importance of proactive communication and documentation throughout the performance period.</p></th><th><p>Determine appropriate strategies for course correction or exit when digital service delivery is off track.</p><p>Demonstrate how to negotiate consideration or remediation actions within the context of agile delivery.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Federal IT Acquisition, Management, and Software Engineering Practices</li><li>Activity: Federal IT Acquisition, Management, and Software Engineering Practices</li><li>Exit Strategy</li><li>Exit Strategy: Key Questions for Analysis</li></ul></th></tr></thead></table>

## Module 5: Grow

Grow: Apply techniques to create the culture of innovation within your sphere that enables you and others to effectively lead and influence customers to the best solutions.

<table><thead><tr><th colspan="3"><p><strong>Module 5: Grow</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 1: Leading Change As An Individual</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Leading Change As An Individual</p></th><th colspan="2"><p>Defines change agents; described effective influence strategies; and approaches to building networks and coalitions to facilitate change</p></th><th><p>Identify your spheres of influence within the acquisition environment.</p><p>Recognize common challenges that arise when engaging stakeholders across those spheres.</p><p>Plan influence strategies and conversations tailored to the challenges and opportunities in your agency or live digital assignment.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Preparing for and Having an Influence Conversation</li><li>Difficult Conversations</li><li>Knowledge Check</li><li>Building Your Resilience</li><li>Cultivating Your Growth Mindset</li><li>Wellness Rituals to Support You in Times of Transition</li><li>Analyze Where the “No” Came From</li><li>Should I Fight This Battle, or How Might I Adjust My Approach To Make It More “Winnable”?</li><li>What to Do When You’re Told No Framework in Action</li><li>Adjust Approach &amp; Identify Lessons Learned</li><li>Telling Your Procurement Story</li></ul></th></tr></thead></table>

<table><thead><tr><th colspan="3"><p><strong>Module 5: Grow</strong></p></th><th></th></tr><tr><th colspan="4"><p><strong>Sprint 2: Leading Organizational Change - Continuous Improvement and Scalable Practices</strong></p></th></tr><tr><th><p><strong>Learning Elements</strong></p></th><th colspan="2"><p><strong>Descriptions</strong></p></th><th><p><strong>Learning Objectives</strong></p></th></tr><tr><th><p>Leading Organizational Change - Continuous Improvement and Scalable Practices</p></th><th colspan="2"><p>This sprint focused on strategies for staying current with emerging technologies and continuously improving acquisition practices, as well as approaches to scaling successful methods across organizations, supported by examples from the broader federal agency community.</p></th><th><p>Assess your strengths and change style to develop a personal plan for contributing to and promoting change within your agency and the broader government community.</p></th></tr><tr><th colspan="4"><p><strong>Topics</strong></p></th></tr><tr><th colspan="4"><ul><li>Staying Current and Driving Change: Your Role in Continuous Improvement</li><li>Staying Current with Emerging Tech and Trends</li><li>Continuous Improvement in Everyday Procurement</li><li>The Case for Creating Practical Guides: From Playbooks to Toolkits and Beyond</li><li>Exploring your role as an ambassador of change</li><li>Kotter Model Introduction</li><li>Self-Assessment: What’s Your Change Style?</li><li>Create Your Change Contribution Plan</li><li>Wrap-Up &amp; Call to Action</li></ul></th></tr></thead></table>

##

## Module 6: Apply skills

Apply: Apply techniques learned in the course through various activities

| **Module 6: Apply** |     |     |
| --- |     |     | --- |
| **Learning Objectives** | Demonstrate the ability to conduct discussions and interviews with stakeholders across your sphere of influence.  <br><br>Apply shadowing, detailed observations, or rotational assignments with digital service experts to better understand and integrate into the culture.  <br><br>Utilize a “small team of teams” approach to design, execute, and reflect on a live digital assignment |     |
| --- | --- |     |
| **Learning Elements** | **Descriptions** |     |
| --- | --- |     |
| Stakeholder Interview Assignment | A structured opportunity for participants to engage agency leaders who influence digital services, procurement, or policy. By conducting 2–4 interviews, participants practice influence, build empathy, and deepen their understanding of organizational dynamics. Full guidance and criteria for this assignment can be found in the Appendix. |     |
| --- | --- |     |
| Shadowing Assignment | An observational learning experience where participants spend at least four hours with a digital service delivery team. By witnessing agile workflows, user-centered design, and cross-functional<br><br>collaboration, participants gain firsthand insight into modern delivery practices. Full guidance and criteria for this assignment can be found in the Appendix. |     |
| --- | --- |     |
| Live Digital Assignment | The program’s capstone project, simulating the full lifecycle of a digital service acquisition. Working in teams, participants identify a real procurement challenge, apply agile and human-centered design principles, and produce proposals, reviews, and presentations. Full guidance and criteria for this assignment can be found in the Appendix. |     |
| --- | --- |     |

**Threaded Scenario Guidance**

# Threaded Case Scenario Guidance

##

## Purpose of case scenario integration

This guide provides a high-level overview of how vendors delivering the DITAP program should approach the integration of a case scenario across the course modules. It outlines the purpose of the case scenario, expectations for integration across the curriculum, and guidance for selecting alternative case studies if needed.

### Case scenario overview

The recommended case scenario for the DITAP program is _Navigating Stakeholder and Decision-Making Challenges,_ written by Cynuria. This case provides a multi-phase scenario aligned with key DITAP competencies and supports learners in connecting theory to practice in a realistic digital acquisition context.

The Cynuria case scenario includes multiple milestones and decision points designed to evolve alongside the course curriculum. It is structured to:

- Introduce a realistic digital acquisition challenge (CRM procurement)
- Showcase policy, technical, and stakeholder complexity
- Enable applied learning through scenario-based activities
- Foreshadow and revisit decision-making moments in alignment with course content

Two versions of the Cynuria case scenario are available:

- **Comprehensive version**: This version includes both facilitator and student guidance. It is structured with clear milestones and aligned touchpoints for integration across modules. It’s the most thorough and detailed resource.
- **Narrative version**: This version presents the same core scenario in a shorter, story-driven format. It’s designed for readability and engagement, and may include narrative cliffhangers to spark discussion. Vendors may choose to use this version as a supplemental or primary reading depending on audience and delivery style.

Vendors are encouraged to use the Cynuria case scenario unless they have a compelling reason to substitute another. If a different case scenario is used, it must:

- Include multiple touchpoints across at least four modules
- Feature a narrative that evolves and builds in complexity
- Include opportunities for stakeholder analysis, solution evaluation, delivery planning, and leadership or change management
- Allow learners to apply frameworks and decision-making tools across modules
- Reflect realistic constraints and trade-offs in government digital acquisition

#### Pacing guide

The threaded case scenario unfolds alongside the course modules, with each activity reinforcing key concepts and building toward an integrated understanding of digital service procurement. Some activities are core milestones drawn directly from the Cynuria case materials; others are extension activities designed to deepen learning or connect to real-world application. The pacing chart below outlines when each case activity appears, which sprint it aligns to, and how it connects to major course milestones.

| **Module** | **Sprint** | **Activity Title** | **Case Scenario Milestone Alignment** |
| --- | --- | --- | --- |
| **Module 1** | Sprint 1 | Introduction to Cynuria Case | Not a formal milestone, serves as Case scenario narrative intro |
| --- | --- | --- | --- |
| **Module 2** | Sprint 1 | Stakeholder Mapping | Milestone 1 |
| --- | --- | --- | --- |
| **Module 2** | Sprint 4 | Market Research Planning | Not a formal milestone, builds on Milestone 1 |
| --- | --- | --- | --- |
| **Module 2** | Sprint 4 | FAR 10 Integration Assignment | Not a formal milestone. It’s an extension activity. |
| --- | --- | --- | --- |
| **Module 3** | Sprint 1 | Solution Evaluation with SWOT Analysis | Milestone 2 |
| --- | --- | --- | --- |
| **Module 3** | Sprint 2 | Evaluating Data Security Solutions with SWOT & Cost Estimation | Milestone 3 |
| --- | --- | --- | --- |
| **Module 3** | Sprint 3 | Designing a Solicitation Strategy | Not a formal milestone, builds on Milestones 2 and 3 |
| --- | --- | --- | --- |
| **Module 4** | Sprint 3 | Laying the Groundwork for Agile Delivery | Applies prior decisions from Milestones 2 and 3 |
| --- | --- | --- | --- |
| **Module 4 or 5** |     | Laying Out a Recommendation | Milestones 4 & 5 |
| --- | --- | --- | --- |
| **Module 5** | Sprint 3 | Leading Change and Navigating Resistance | Integrates entire case context |
| --- | --- | --- | --- |

####

#### Integration guidance

Vendors are responsible for ensuring the case scenario is threaded throughout the curriculum in a way that:

- Aligns with the learning objectives of each module
- Reinforces key digital service delivery principles and practices
- Provides a common anchor for group discussion, assignments, and applied activities

Integration may vary slightly depending on program design, but generally includes:

- Early exposure to the full case scenario (Module 1)
- Deep dives into individual milestones aligned with module competencies (Modules 2–3)
- Continued reference during planning and implementation content (Modules 4–5).
- Synthesis and final presentation using the case (Module 6)

Vendors should ensure that:

- Participants receive the full case scenario early in the program
- Assigned readings are clearly communicated in advance of each module
- Participants are given multiple opportunities to apply tools and concepts to the case throughout the course

## Facilitating the threaded case study

### General facilitator guidance

#### Purpose of the case scenario

The threaded case scenario is a tool for deepening understanding and sparking application across the course. Through a fictional—but realistic—procurement scenario, participants explore the complexity of digital service delivery in government and connect course concepts to their own day-to-day challenges. The case scenario helps participants:

- Apply concepts in a realistic, evolving context.
- Practice critical thinking, stakeholder engagement, and strategic decision-making.
- Surface parallels to their own work and identify opportunities for influence and improvement.

Each case scenario activity reinforces the sprint’s learning objectives and serves as a springboard for meaningful, context-specific conversation.

_Detailed guidance for each activity—including suggested framing, timing, and prompts—is available in the corresponding_ [_facilitator guide_](https://docs.google.com/document/d/1vCYu47Dgk5jHrD7I0D3vGyuCO3VNjBFvOxUpNyciiso/edit?tab=t.apa36gofaswq)_._

### Flexible format

Most case activities are run in small groups with a brief whole-group share-out. Refer to the [pacing guide](#kix.khaakwe7pvo9) for timing recommendations and feel free to adjust based on group size, energy, and time available. There’s plenty more room for creativity in how you run these sessions. Think of what’s provided as a springboard.

### Key facilitation moves

**Anchor in course content  
**Use the case scenario to reinforce frameworks and key ideas introduced in each sprint—drawing from both live session slides and self-paced materials.

**Create call-back moments  
**Encourage learners to connect current decisions to earlier moments in the case or in their own work. What patterns or assumptions are still at play? How have past decisions shaped the present?

**Promote evidence-based reasoning  
**Ask learners to ground their analysis in specific details from the case—emails, timelines, decisions, and organizational behavior.

**Bridge to lived experience  
**If groups get stuck, invite reflection on their own environments. What makes collaboration hard across functions? What constraints or opportunities do they see in their work?

**Challenge assumptions  
**Prompt participants to identify and question assumptions Casey’s team may be making. What’s being overlooked? What alternate paths are possible?

**Broaden perspectives  
**Encourage groups to consider nontraditional sources of insight, such as frontline staff, legacy system documentation, or indirect stakeholders.

**Connect discovery to design  
**Especially in Modules 2–3, guide learners to see how early discovery findings shape later acquisition and implementation decisions.

**Elevate learner expertise  
**Your role is to create space for rich discussion—not to lecture. Emphasize the expertise in the room.

**Right-size the vendor role  
**Encourage analysis of how participants themselves can lead and influence—rather than focusing only on vendor behavior or external constraints.  

**LMS Guidance**

# LMS Guidance

As part of the course introduction, vendors should provide learners with a brief orientation to the Learning Management System (LMS). This orientation should be tailored to the specific LMS being used and designed to help learners feel comfortable navigating the system from the start. The goal is to set learners up for success, reduce confusion, and ensure they can focus on the course content.

## Key elements to cover in your LMS orientation include

**Accessing the LMS:** Provide clear instructions for logging in, setting up accounts, and accessing the course. Include relevant links and any credentials learners may need.

**Course layout and structure:** Give an overview of how the course is organized, including the modules, lessons, and any assessments. Highlight where learners should begin and the recommended progression through the content.

**Finding key course elements:** Show learners where to locate modules, assignments, assessments, required materials, and other resources. Clear navigation instructions will help learners find what they need quickly.

**Tracking progress:** Explain any progress indicators available in the LMS, such as completed modules or scores, and how learners can use these tools to monitor their own learning.

**Communication tools:** Outline how learners can interact with instructors/facilitators, support staff, and peers. This might include discussion boards, messaging features, announcements, or office hours.

**Technical support:** Provide information on how learners can get help if they encounter technical issues, including contact points and response expectations.

## Integrating materials into your LMS

Vendors should ensure that all course materials, modules, assessments, and other materials are properly integrated into their LMS. This includes uploading files, linking to external resources, and configuring assessments so that learner progress and completion are tracked accurately. Clear labeling, consistent module sequencing, and accessible navigation are critical to providing a seamless learner experience. Whenever possible, test the course in the LMS environment before launch to confirm that all interactive content, links, and tracking functions work as intended.

Vendors should design and integrate course materials in accordance with accessibility standards, ensuring all learners, including those with disabilities, can engage with the content. This includes providing alternative text for images, captions or transcripts for videos, keyboard navigation for interactive elements, and clear, consistent formatting for readability. Vendors should also ensure that color choices, font sizes, and contrast meet accessibility guidelines, and that all links and instructions are clear and descriptive. Incorporating these practices from the start helps provide an inclusive learning experience and supports compliance with accessibility requirements.

### LiaScript integration

This course was built using LiaScript, an open-source framework for interactive online learning. LiaScript allows for dynamic content, such as embedded quizzes, multimedia, and branching scenarios. Learners can complete exercises directly within the course environment, receive immediate feedback, and track their progress in real time. For course providers, LiaScript supports flexible formatting and consistent presentation across modules, making it easier to maintain quality and accessibility standards.




