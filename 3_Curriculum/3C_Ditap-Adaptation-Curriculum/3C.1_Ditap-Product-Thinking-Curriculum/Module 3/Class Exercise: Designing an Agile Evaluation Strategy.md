# Class Exercise: Designing an Agile Evaluation Strategy

Now it’s your turn to design an agile evaluation strategy. Using your ESA scenario, draft a phased evaluation approach that reflects your team’s readiness and supports the goals of modern digital delivery. Focus on selecting a vendor who can collaborate, iterate, and solve real user problems—just like in the VA.gov case study.

Apply the principles of agile acquisition to develop a phased evaluation strategy for the procurement of the Emotional Support Animal (ESA) Registry. Your strategy should reflect your agency’s digital maturity, mission needs, and the practical realities of vendor evaluation in a federal context.

## Exercise instructions:

**Scenario Setup:**   
Your agency is preparing to acquire a modern, user-centered ESA Registry to support verification, renewals, and ongoing service delivery. Leadership supports agile methods, but your team is still building confidence and experience with agile evaluations. You understand the value of a down-select process but haven’t implemented one before.

**Your Task**  
With your team, design a high-level evaluation strategy that prioritizes real-world vendor performance—not just well-written proposals. Your plan should reflect what you *need to see and test* to select a vendor capable of delivering iteratively and in collaboration with your team.

**1\. Define Evaluation Phases**

* How many phases will your process include?  
* What will each phase consist of (e.g., case studies, written responses, team interviews, technical demonstrations)?  
* Which phases will be formally evaluated, and which will be informational or non-evaluated?

**2\. Identify Evaluation Criteria**

* What capabilities or behaviors do you want to assess (e.g., agile practices, technical depth, user-centered design)?  
* How will you balance experience with past performance?

**3\. Draft Proposal Instructions**

* What will you ask vendors to submit?  
* Will you require a live demonstration or working session?  
* How will you ensure instructions are clear, fair, and realistic for your evaluation team?

**4\. Address Collaboration and Governance**

* How will you work with your Contracting Officer throughout the process?  
* What role will your team play in shaping the PWS or SOO?  
* How will you prepare your evaluation team to assess proposals and demos effectively?

**Deliverable**

Prepare a short written summary of your proposed evaluation approach, including your rationale for structure, criteria, and process. Be ready to present key elements to the class.

**Activity Tip:**  
Refer back to the [VA.gov Modernization Case Study](?tab=t.fs6wdx28w64a) for inspiration—but ground your plan in your team’s current level of digital maturity and readiness. Your strategy doesn’t have to be perfect—it just needs to be intentional, actionable, and aligned with agile values.

## Module 2 Exercise Instructions Answer Key

Part A: Persona-based vision development (25 minutes) 

Team assignment framework:

Team Greg (Innovation/Green Quadrant) \- Expected outputs:

Problem statement:

* Target answer: "Healthcare providers cannot access cutting-edge AI insights that could revolutionize patient care and medical research, limiting breakthrough discoveries and innovative treatments."

* Who experiences this: Research scientists, data analysts, innovative clinicians, and academic medical centers

* Facilitator notes: Green teams often focus on technological possibilities rather than user problems. Guide them to ground innovation in actual user needs.

Target users:

* Primary users: Research scientists, data analysts, clinical researchers, innovative physicians

* Secondary users: Academic institutions, pharmaceutical companies, medical device manufacturers

* Facilitator notes: Ensure they include actual end-users, not just technology enthusiasts. Push for specific user personas.

Value proposition:

* Target answer: "First-to-market AI capabilities that unlock medical breakthroughs impossible with traditional data analysis, accelerating discovery and improving patient outcomes."

* Facilitator notes: Help them connect innovation to concrete user benefits, not just technical capabilities.

Success metrics:

* Expected metrics: Number of new insights discovered, research papers published, breakthrough treatments identified, time to discovery, competitive advantage measures

* Facilitator notes: Push for measurable outcomes that demonstrate real-world impact, not just usage statistics.

Vision statement:

* Target answer: "Rainbo transforms healthcare through AI-powered discoveries that save lives and advance medical science."

* Facilitator notes: Should be inspiring but grounded in achievable outcomes. Avoid a pure technology focus.

Team Roman (Control/Red Quadrant) \- Expected outputs:

Problem statement:

* Target Answer: "Healthcare data systems lack the reliability, security, and compliance necessary for safe, effective patient care, creating risks for patient safety and regulatory violations."

* Who experiences this: Healthcare administrators, compliance officers, system operators, risk managers

* Facilitator notes: Red teams may focus too heavily on process without connecting to user impact. Help them articulate the user consequences of unreliable systems.

Target users:

* Primary users: Healthcare administrators, compliance officers, system operators, security personnel

* Secondary users: Patients (through safety), regulators, insurance providers

* Facilitator notes: Ensure they consider end-user impact, not just administrative convenience.

Value proposition:

* Target answer: "Reliable, compliant, and auditable healthcare data management that ensures patient safety, regulatory compliance, and operational predictability."

* Facilitator notes: Help them articulate positive value, not just risk avoidance.

Success metrics:

* Expected metrics: System uptime percentage, compliance audit results, error reduction rates, security incident frequency, and regulatory approval speed

* Facilitator notes: Balance process metrics with outcome measures that show real-world impact.

Vision statement:

* Target answer: "Rainbo provides the reliable, compliant healthcare data foundation that enables safe, effective patient care."

* Facilitator notes: Should emphasize enabling positive outcomes, not just preventing problems.

Team Yvette (Inclusion/Yellow Quadrant) \- Expected outputs:

Problem statement:

* Target answer: "Healthcare teams cannot collaborate effectively due to fragmented data systems and communication silos, preventing coordinated patient care and knowledge sharing."

* Who experiences this: Healthcare teams, interdisciplinary care providers, patient advocates, care coordinators

* Facilitator notes: Yellow teams may focus on process harmony without connecting to patient outcomes. Guide them toward collaboration that improves care.

Target users:

* Primary users: Interdisciplinary healthcare teams, care coordinators, patient advocates, clinical social workers

* Secondary users: Patients and families, healthcare administrators, quality improvement teams

* Facilitator notes: Ensure they focus on users who need to collaborate, not just those who like collaboration.

Value proposition:

* Target answer: "Collaborative healthcare data platform that brings teams together around patient needs, improving care coordination and knowledge sharing."

* Facilitator notes: Help them connect collaboration to better patient outcomes, not just better relationships.

Success metrics:

* Expected metrics: Team collaboration frequency, cross-functional communication rates, care coordination effectiveness, user satisfaction, patient outcome improvements

* Facilitator notes: Push for metrics that demonstrate the impact of collaboration on patient care, not just team satisfaction.

Vision statement:

* Target answer: "Rainbo connects healthcare teams through shared data and collaborative tools that put patients at the center of care."

* Facilitator notes: Should emphasize patient-centered outcomes, not just team harmony.

Team Barb (Urgency/Blue Quadrant) \- Expected outputs:

Problem statement:

* Target answer: "Healthcare providers are losing the fight against disease due to slow, fragmented data access that delays critical decisions and prevents timely interventions."

* Who experiences this: Front-line clinicians, emergency responders, critical care teams, patients with urgent needs

* Facilitator notes: Blue teams may prioritize speed over quality. Help them balance urgency with effectiveness.

Target users:

* Primary users: Front-line clinicians, emergency responders, critical care teams, urgent care providers

* Secondary users: Patients with time-sensitive conditions, healthcare administrators, quality improvement teams

* Facilitator notes: Ensure they consider users who need speed for mission-critical decisions, not just impatient users.

Value proposition:

* Target answer: "Rapid access to comprehensive healthcare data that enables life-saving decisions and competitive advantage in patient care."

* Facilitator notes: Help them articulate how speed improves outcomes, not just user convenience.

Success metrics:

* Expected metrics: Time to diagnosis, treatment effectiveness, patient outcomes, competitive position, response time improvements

* Facilitator notes: Focus on outcome metrics that justify urgency, not just speed for its own sake.

Vision statement:

* Target answer: "Rainbo delivers the speed and insights healthcare providers need to win the fight for better patient outcomes."

* Facilitator notes: Should emphasize winning for patients, not just organizational competition.

### 

### Facilitator Guidance for Part A:

Common challenges and interventions:

* Technology focus: Teams often prioritize technical features over user problems. Redirect with "How does this help users accomplish their goals?"

* Internal perspective: Teams may describe organizational needs rather than user needs. Ask "Who is the actual person using this system?"

* Generic solutions: Teams may create vague, one-size-fits-all visions. Push for specific, persona-driven insights.

* Metric confusion: Teams may opt for easy-to-measure metrics over meaningful outcomes. Guide toward impact measurement.

Quality indicators:

* Good vision: Specific user focus, clear problem articulation, measurable outcomes, inspiring but achievable

* Poor vision: Generic statements, technology-focused, unmeasurable goals, unrealistic expectations

Part B: Stakeholder Alignment Challenge (20 minutes) 

Rotation process framework:

Instructions for teams:

1. Spend 5 minutes viewing each team's vision canvas

2. Document alignment opportunities and conflicts

3. Propose integration strategies

4. Return to the original canvas with insights

Expected alignment opportunities:

Cross-quadrant synergies:

* Green \+ Red: Innovation within compliance frameworks creates sustainable breakthroughs

* Yellow \+ Blue: Collaborative approaches can accelerate delivery through better coordination

* Green \+ Blue: Rapid innovation creates competitive advantage in healthcare markets

* Red \+ Yellow: Systematic approaches with inclusive input improve both compliance and adoption

Shared values across quadrants:

* Patient outcomes: All quadrants ultimately serve to improve healthcare delivery

* Data quality: Reliable, accurate data serves innovation, compliance, collaboration, and speed

* User success: Different users need different things, but all need successful outcomes

* System integration: All approaches require effective integration of disparate data sources

Expected potential conflicts:

Diagonal tensions (most common):

* Green vs. Red: Innovation speed vs. compliance thoroughness

* Yellow vs. Blue: Consensus-building vs. rapid decision-making

* Green vs. Red: Experimentation vs. predictable processes

* Yellow vs. Blue: Inclusive participation vs. competitive focus

Specific conflict examples:

* Speed vs. Quality: Blue urgency may conflict with Red quality requirements

* Innovation vs. Stability: Green experimentation may threaten Red's reliability needs

* Consensus vs. Efficiency: Yellow inclusion may slow Blue delivery timelines

* Individual vs. Team: Blue competition may conflict with Yellow collaboration

Integration strategies \- Expected approaches:

Phased implementation:

* Phase 1: Establish a reliable foundation (Red) with collaborative processes (Yellow)

* Phase 2: Add innovation capabilities (Green) while maintaining quality standards

* Phase 3: Optimize for speed and outcomes (Blue) while preserving earlier investments

Parallel development:

* Core platform: Red-focused reliability and compliance

* Innovation layer: Green-focused experimentation and new capabilities

* Collaboration tools: Yellow-focused team coordination and communication

* Performance optimization: Blue-focused speed and competitive advantage

Integrated governance:

* Multi-perspective decision-making: Include all quadrants in major decisions

* Balanced metrics: Measure success across all quadrant priorities

* Flexible processes: Adapt approaches based on project phase and needs

* Risk-based prioritization: Balance competing priorities based on mission impact

### Facilitator guidance for Part B:

Rotation management:

* Time keeping: Enforce 5-minute rotations to maintain energy and focus

* Documentation: Provide structured templates for capturing insights

* Facilitation questions: 

  * "Where do you see natural alignment between these approaches?"

  * "What tensions need executive decision-making?"

  * "How could these approaches strengthen each other?"

Common insights:

* False dichotomies: Teams often discover they created either/or choices when both/and is possible

* Complementary strengths: Different quadrants address different risks and opportunities

* Timing matters: Different quadrants may be appropriate at different project phases

* Integration complexity: Successful solutions require sophisticated integration, not simple compromise

Quality indicators:

* Good integration: Specific examples of realistic conflict resolution, and creative solutions

* Poor integration: Generic compromise, avoidance of real tensions, unrealistic harmony assumptions

### Part C: Executive Synthesis (15 minutes) 

Collaborative process framework:

Synthesis process:

1. Share key insights from Part B (5 minutes)

2. Identify common themes and integration opportunities (5 minutes)

3. Develop a unified vision statement (5 minutes)

Expected unified vision \- Sample answer:

Integrated vision statement: "Rainbo creates a reliable, collaborative healthcare data platform that enables rapid innovation and evidence-based decision-making, ultimately delivering better patient outcomes through trusted technology and empowered healthcare teams."

Supporting framework:

* Foundation (Red): Reliable, compliant data management that ensures patient safety

* Process (Yellow): Collaborative, inclusive development that serves all stakeholders

* Innovation (Green): AI-powered insights and breakthrough discovery capabilities

* Outcomes (Blue): Rapid, effective patient care that achieves competitive advantage

Integration elements \- Expected components:

Problem integration: "Healthcare providers face fragmented, unreliable data systems that prevent both breakthrough discoveries and timely patient care, while requiring collaborative solutions that meet strict compliance requirements."

User integration:

* Primary users: Healthcare providers across all specialties and settings

* Secondary users: Patients, researchers, administrators, regulators

* Tertiary users: Healthcare system stakeholders, technology partners, policymakers

Value proposition integration: "Comprehensive healthcare data platform that combines reliability, collaboration, innovation, and speed to transform patient care and medical research."

Metrics integration:

* Reliability metrics: System uptime, data accuracy, compliance scores

* Collaboration metrics: Team coordination, cross-functional communication, user satisfaction

* Innovation metrics: Discoveries, research acceleration, breakthrough treatments

* Outcome metrics: Patient outcomes, care speed, competitive advantage

Facilitator guidance for Part C:

Synthesis facilitation:

* Encourage specificity: Push for concrete examples rather than abstract concepts

* Manage complexity: Help teams balance comprehensiveness with clarity

* Focus on integration: Emphasize how different elements work together, not just coexist

* Reality check: Ensure a unified vision is achievable given organizational constraints

Common synthesis patterns:

* Layered approach: Different quadrants address different system layers

* Phased evolution: Quadrants dominate different project phases

* Parallel development: Multiple approaches developed simultaneously

* Integrated governance: All perspectives included in decision-making

Quality indicators:

* Sound synthesis: Clear integration logic, maintains quadrant strengths, addresses real tensions, and provides actionable direction

* Poor synthesis: Generic compromise, loses quadrant distinctiveness, avoids difficult trade-offs, unclear implementation

### HCD Exercise Answer Key

Round 1: Problem discovery (5 minutes) \- Expected outcomes

Effective questions framework:

"Who" questions:

* "Who are the actual users of this procurement process?"

* "Who gets frustrated when this process doesn't work?"

* "Who has to work around the current system?"

* "Who makes decisions based on this process?"

* "Who benefits when this process works well?"

"Why" questions:

* "Why do users need this process to work?"

* "Why does the current approach create problems?"

* "Why haven't these problems been solved before?"

* "Why is this important to users' daily work?"

* "Why do current workarounds exist?"

"What" questions:

* "What are users trying to accomplish?"

* "What prevents them from being successful?"

* "What would success look like from their perspective?"

* "What happens when the process fails?"

* "What would users do if this process didn't exist?"

Expected insights from Round 1:

User-centered discoveries:

* The "customer" for procurement is often the program manager or end user, not the contracting officer

* Users care about outcomes and timelines, not process compliance

* Process steps that seem logical to procurement may be obstacles to users

* Users develop workarounds that reveal unmet needs and system failures

* User frustration often stems from a lack of transparency and predictability

Problem reframing:

* Original problem: "Our procurement process takes too long."

* Reframed problem: "Program managers can't predict when they'll receive needed services, preventing effective project planning."

* Original problem: "Vendors complain about our requirements."

* Reframed problem: "Current requirements don't help vendors understand what success looks like, leading to poor proposals."

Round 2: Solution ideation (10 minutes) \- Expected outcomes

Process redesign:

* Streamline approval workflows to reduce handoffs

* Eliminate redundant reviews and approvals

* Create parallel processing for non-dependent activities

* Implement risk-based approval levels

Communication improvement:

* Regular status updates with clear timelines

* Transparent communication about delays and changes

* User-friendly dashboards showing process progress

* Proactive notification of potential issues

Tool enhancement:

* User-friendly interfaces that don't require training

* Automated notifications and reminders

* Mobile-accessible status checking

* Integration with users' existing tools

Training and support:

* User education about process requirements and timelines

* Help desk resources for process questions

* Documentation written for users, not procurement specialists

* Mentoring programs for new users

Policy clarification:

* Clear guidance on requirements vs. preferences

* Exception processes for unusual circumstances

* Standardized templates and examples

* Regular policy updates based on user feedback

Round 3: Solution integration (5 minutes) \- Expected outcomes

User impact assessment:

* How much does this improve the user experience?

* How many users benefit from this change?

* How frequently will users encounter this improvement?

* How significant is the improvement in user success?

Implementation feasibility:

* Can this be implemented with available resources?

* What organizational changes are required?

* How long will the implementation take?

* What resistance should we expect?

Systemic change potential:

* Does this address root causes or just symptoms?

* Will this prevent similar problems in the future?

* How does this improve the overall system?

* What other processes might benefit from similar changes?

Scalability assessment:

* Can this solution be applied across various procurement scenarios?

* How easily can this be adapted to other contexts?

* What training or support is needed for widespread adoption?

* How will this solution evolve?

### HCD exercise debrief \- Answer key

Question: How did the HCD approach change your understanding of the problem?

Expected answer: The HCD approach typically reveals that procurement challenges are often user experience problems rather than purely technical or policy issues. Participants usually find that focusing on user needs reveals solutions that wouldn't emerge from process-focused analysis.

Key learning points:

* User perspective shift: Moving from "how do we fix our process?" to "how do we help users succeed?" often reveals different problems entirely

* Root cause discovery: User research uncovers underlying issues that aren't apparent from process analysis alone

* Solution reframing: Solutions that serve user needs often improve process efficiency as a side benefit

* Complexity reduction: User-focused solutions often eliminate unnecessary complexity that exists only for internal reasons

Question: What surprised you about focusing on users rather than processes?

Expected answer: Most participants are surprised by how much complexity they can eliminate by prioritizing user outcomes over process compliance. They often discover that many procedural requirements don't actually serve user needs and may actively impede mission success.

Key learning points:

* Unnecessary complexity: Many process steps exist for historical reasons rather than current needs

* User workarounds: Users often create informal solutions that work better than official processes

* Outcome focus: Users care about results, not the specific steps to achieve them

* Efficiency opportunities: User-centered approaches often improve both experience and efficiency

Question: How can executives create space for this type of discovery?

Expected answer: Executives can create space by protecting time for user research, encouraging teams to question existing processes, and demonstrating that user outcomes are valued over process perfection. This approach requires cultural change and explicit permission to challenge the status quo.

Key learning points:

* Time protection: User research requires dedicated time that must be protected from other priorities

* Cultural permission: Teams need explicit permission to question existing processes and propose changes

* Outcome prioritization: Executive messaging must emphasize user success over process compliance

* Change support: Leaders must support teams who propose modifications based on user research

### Facilitator notes for HCD exercise:

Setup considerations:

* Role clarity: Ensure participants understand their roles and rotate properly

* Problem selection: Encourage real problems that participants have experienced

* Time management: Enforce time limits to maintain energy and focus

* Documentation: Provide templates for capturing insights

Common challenges:

* Process focus: Participants may default to process improvement rather than user focus

* Solution jumping: Teams may jump to solutions without understanding problems

* Generic problems: Participants may choose abstract rather than specific problems

* Consultant bias: Consultants may give advice rather than asking questions

Facilitation interventions:

* Redirect to users: "Who specifically experiences this problem?"

* Slow down solutions: "What else do we need to understand about this problem?"

* Encourage specificity: "Can you give me a specific example?"

* Focus on outcomes: "What would success look like for users?"

Success indicators:

* Good discovery: Specific user insights, problem reframing, unexpected discoveries

* Poor discovery: Generic process complaints, obvious solutions, no new insights

* Good solutions: User-focused, creative, address root causes

* Poor solutions: Process-focused, obvious, treat symptoms only

